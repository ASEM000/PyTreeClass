{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🍳  Common recipes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section introduces common recipes you might need while using `PyTreeClass` to train/build models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Add a leaf to the instance after instantiation.\n",
    "\n",
    "The following recipe, adds a method `add_leaf` that sets a leaf value and name. however, since this method mutate the internal state of the instance `.at['add_leaf']` is used to apply the method functionally and return method call value and a **new** instance ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tree(a=1.0, b=2.0, c=3.0, d=4.0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytreeclass as pytc\n",
    "\n",
    "\n",
    "class Tree(pytc.TreeClass):\n",
    "    a: float = 1.0\n",
    "    b: float = 2.0\n",
    "    c: float = 3.0\n",
    "\n",
    "    def add_leaf(self, name: str, value):\n",
    "        setattr(self, name, value)\n",
    "\n",
    "\n",
    "tree = Tree()\n",
    "# Tree(a=1.0, b=2.0, c=3.0)\n",
    "\n",
    "_, tree_with_d = tree.at[\"add_leaf\"](\"d\", 4.0)\n",
    "\n",
    "tree_with_d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Customize optimizers-leaf updates using `PyTreeClass` mask + `Optax`.\n",
    "The following recipe, `optax.masked` is used to apply certain optmizers to certain leaves using masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "import pytreeclass as pytc\n",
    "import jax\n",
    "\n",
    "\n",
    "class Tree(pytc.TreeClass):\n",
    "    a: float = 1.0\n",
    "    b: float = 2.0\n",
    "    c: float = 3.0\n",
    "\n",
    "\n",
    "tree = Tree()\n",
    "\n",
    "false_mask = tree.at[...].set(False)\n",
    "\n",
    "a_mask = false_mask.at[\"a\"].set(True)\n",
    "b_mask = false_mask.at[\"b\"].set(True)\n",
    "c_mask = false_mask.at[\"c\"].set(True)\n",
    "\n",
    "optim = optax.chain(\n",
    "    # update `a` with sgd of learning rate 1\n",
    "    optax.masked(optax.sgd(learning_rate=1), a_mask),\n",
    "    # update `b` with sgd of learning rate -1\n",
    "    optax.masked(optax.sgd(learning_rate=-1), b_mask),\n",
    "    # update `c` with sgd of learning rate 0\n",
    "    optax.masked(optax.sgd(learning_rate=0), c_mask),\n",
    ")\n",
    "\n",
    "\n",
    "# freeze non-differentiable parameters\n",
    "# in this case all parameters are differentiable\n",
    "# but we do it incase we add a non-differentiable parameter later\n",
    "tree = tree.at[jax.tree_map(pytc.is_nondiff, tree)].apply(pytc.freeze)\n",
    "\n",
    "optim_state = optim.init(tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Use `numpy` functions on `TreeClass` instance.\n",
    "`jax.numpy` functions can be applied to `TreeClass` instance using a function transformation `bcmap` around the `numpy` function and enabling the feature through `leafwise=True`. `leafwise=True` additionally enable math operation per-leaf, for example `tree`+1 will add 1 to all leaves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(a=0, b=(0.0, 103.0), c=[104. 105. 106.])\n",
      "Tree(a=1, b=(102.0, 103.0), c=[104. 105. 106.])\n",
      "Tree(a=1, b=(102.0, 103.0), c=[104. 105. 106.])\n"
     ]
    }
   ],
   "source": [
    "import pytreeclass as pytc\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "class Tree(pytc.TreeClass, leafwise=True):\n",
    "    a: int = 1\n",
    "    b: tuple[float] = (2.0, 3.0)\n",
    "    c: jax.Array = jnp.array([4.0, 5.0, 6.0])\n",
    "\n",
    "\n",
    "tree = Tree()\n",
    "\n",
    "# make where work with arbitrary pytrees\n",
    "tree_where = pytc.bcmap(jnp.where)\n",
    "\n",
    "print(tree_where(tree > 2, tree + 100, 0))\n",
    "# Tree(a=0, b=(0.0, 103.0), c=[104. 105. 106.])\n",
    "\n",
    "print(tree.at[tree > 1].apply(lambda x: x + 100))\n",
    "# Tree(a=1, b=(102.0, 103.0), c=[104. 105. 106.])\n",
    "\n",
    "mask = tree_where(tree > 1, True, False)\n",
    "print(tree.at[mask].apply(lambda x: x + 100))\n",
    "# Tree(a=1, b=(102.0, 103.0), c=[104. 105. 106.])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] Use visualization tools with arbitrary pytrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list\n",
      "├── [0]=1\n",
      "├── [1]=[...]\n",
      "└── [2]=4\n",
      "list\n",
      "├── [0]=1\n",
      "├── [1]:list\n",
      "│   ├── [0]=2\n",
      "│   └── [1]=3\n",
      "└── [2]=4\n",
      "┌────┬────┬─────┐\n",
      "│Name│Type│Count│\n",
      "├────┼────┼─────┤\n",
      "│[0] │int │1    │\n",
      "├────┼────┼─────┤\n",
      "│[1] │list│1    │\n",
      "├────┼────┼─────┤\n",
      "│[2] │int │1    │\n",
      "├────┼────┼─────┤\n",
      "│Σ   │list│3    │\n",
      "└────┴────┴─────┘\n",
      "┌──────┬────┬─────┐\n",
      "│Name  │Type│Count│\n",
      "├──────┼────┼─────┤\n",
      "│[0]   │int │1    │\n",
      "├──────┼────┼─────┤\n",
      "│[1][0]│int │1    │\n",
      "├──────┼────┼─────┤\n",
      "│[1][1]│int │1    │\n",
      "├──────┼────┼─────┤\n",
      "│[2]   │int │1    │\n",
      "├──────┼────┼─────┤\n",
      "│Σ     │list│4    │\n",
      "└──────┴────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import pytreeclass as pytc\n",
    "\n",
    "tree = [1, [2, 3], 4]\n",
    "\n",
    "print(pytc.tree_diagram(tree, depth=1))\n",
    "print(pytc.tree_diagram(tree, depth=2))\n",
    "print(pytc.tree_summary(tree, depth=1))\n",
    "print(pytc.tree_summary(tree, depth=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5] Using `callbacks` to validate/convert inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On applying Range(min=1, max=100) for field=`in_dim`:\n",
      "0 not in range [1, 100]\n",
      "On applying IsInstance(klass=<class 'int'>) for field=`in_dim`:\n",
      "1.0 not an instance of <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import pytreeclass as pytc\n",
    "\n",
    "\n",
    "# you can use any function\n",
    "class Range(pytc.TreeClass):\n",
    "    min: int | float = -float(\"inf\")\n",
    "    max: int | float = float(\"inf\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not (self.min <= x <= self.max):\n",
    "            raise ValueError(f\"{x} not in range [{self.min}, {self.max}]\")\n",
    "        return x\n",
    "\n",
    "\n",
    "class IsInstance(pytc.TreeClass):\n",
    "    klass: type | tuple[type, ...]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not isinstance(x, self.klass):\n",
    "            raise TypeError(f\"{x} not an instance of {self.klass}\")\n",
    "        return x\n",
    "\n",
    "\n",
    "class Foo(pytc.TreeClass):\n",
    "    # allow in_dim to be an integer between [1,100]\n",
    "    in_dim: int = pytc.field(callbacks=[IsInstance(int), Range(1, 100)])\n",
    "\n",
    "\n",
    "tree = Foo(1)\n",
    "# no error\n",
    "\n",
    "try:\n",
    "    tree = Foo(0)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    tree = Foo(1.0)\n",
    "except TypeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [6] Freeze custom parameters using `.at` manually/with mask\n",
    "\n",
    "In the following example,  some classes like `Dropout`, can contain some leaves that are differentiable,\n",
    "but we do not wish to update them. in `Dropout` Example, the `drop_rate` is a float that\n",
    "should not be updated by optimization. the following recipe shows how to deal with such values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout(drop_rate=108.0)\n",
      "Dropout(drop_rate=0.0)\n"
     ]
    }
   ],
   "source": [
    "import pytreeclass as pytc\n",
    "import jax\n",
    "\n",
    "\n",
    "class Dropout(pytc.TreeClass):\n",
    "    drop_rate: float = 0.0  # dropout rate, 0 mean no dropout\n",
    "\n",
    "    def __call__(self, x, *, key):\n",
    "        keep_rate = 1.0 - self.drop_rate\n",
    "        mask = jax.random.bernoulli(key, keep_rate, x.shape)\n",
    "        return jnp.where(mask, x / keep_rate, 0.0)\n",
    "\n",
    "\n",
    "x = jnp.arange(10)\n",
    "dropout = Dropout(drop_rate=0.5)\n",
    "dropout(x, key=jax.random.PRNGKey(0))\n",
    "\n",
    "\n",
    "@jax.grad\n",
    "def f(layer: Dropout, x: jax.Array):\n",
    "    return layer(x, key=jax.random.PRNGKey(0)).sum()\n",
    "\n",
    "\n",
    "print(f(dropout, x))\n",
    "# Dropout(drop_rate=108.0)  # <--- this is the gradient which is undesired\n",
    "\n",
    "\n",
    "# lets fix this by freezing the dropout rate\n",
    "class Dropout(pytc.TreeClass):\n",
    "    drop_rate: float = pytc.field(callbacks=[pytc.freeze], default=0.0)\n",
    "\n",
    "    def __call__(self, x, *, key):\n",
    "        keep_rate = 1.0 - self.drop_rate\n",
    "        mask = jax.random.bernoulli(key, keep_rate, x.shape)\n",
    "        return jnp.where(mask, x / keep_rate, 0.0)\n",
    "\n",
    "\n",
    "x = jnp.arange(10)\n",
    "dropout = Dropout(drop_rate=0.5)\n",
    "\n",
    "dropout\n",
    "# Dropout(drop_rate=#0.5)  # -> dropout rate is frozen, to call dropout layer we need to unfreeze it first\n",
    "\n",
    "\n",
    "@jax.grad\n",
    "def f(layer: Dropout, x: jax.Array):\n",
    "    layer = jax.tree_map(pytc.unfreeze, layer, is_leaf=pytc.is_frozen)\n",
    "    return layer(x, key=jax.random.PRNGKey(0)).sum()\n",
    "\n",
    "\n",
    "f(dropout, x)\n",
    "# Dropout(drop_rate=#0.5)  # <- dropout rate is not updated, can be used safely with optax\n",
    "\n",
    "\n",
    "# lets say, for evaluation we want to set the dropout rate to 0.0\n",
    "# then we can do the following\n",
    "\n",
    "disable_dropout = dropout.at[\"drop_rate\"].set(0.0, is_leaf=pytc.is_frozen)\n",
    "print(disable_dropout)\n",
    "# Dropout(drop_rate=0.0)  # now the dropout rate is 0. and unfrozen.\n",
    "# this layer is now safe to use for evaluation without special handling (like eval in pytorch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [7] Use `PyTreeClass` with `Flax`/`Equinox`\n",
    "The following recipe adds `at` support for `Flax` and `Equinox`. note for equinox use `eqx.Module` instead of `struct.PyTreeNode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlaxTree(a=1, b=(2.0, 3.0), c=f32[3](μ=5.00, σ=0.82, ∈[4.00,6.00]))\n",
      "FlaxTree(a=1, b=(2.0, 3.0), c=[4. 5. 6.])\n",
      "FlaxTree\n",
      "├── .a=1\n",
      "├── .b:tuple\n",
      "│   ├── [0]=2.0\n",
      "│   └── [1]=3.0\n",
      "└── .c=f32[3](μ=5.00, σ=0.82, ∈[4.00,6.00])\n",
      "┌─────┬────────┬─────┐\n",
      "│Name │Type    │Count│\n",
      "├─────┼────────┼─────┤\n",
      "│.a   │int     │1    │\n",
      "├─────┼────────┼─────┤\n",
      "│.b[0]│float   │1    │\n",
      "├─────┼────────┼─────┤\n",
      "│.b[1]│float   │1    │\n",
      "├─────┼────────┼─────┤\n",
      "│.c   │f32[3]  │3    │\n",
      "├─────┼────────┼─────┤\n",
      "│Σ    │FlaxTree│6    │\n",
      "└─────┴────────┴─────┘\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FlaxTree(a=10, b=(2.0, 3.0), c=f32[3](μ=5.00, σ=0.82, ∈[4.00,6.00]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "import pytreeclass as pytc\n",
    "from flax import struct\n",
    "\n",
    "import jax\n",
    "import pytreeclass as pytc\n",
    "from flax import struct\n",
    "\n",
    "# note that flax is registered with `jax.tree_util.register_pytree_with_keys`\n",
    "# otherwise for arbitrary objects you need to do the key registration\n",
    "\n",
    "\n",
    "class FlaxTree(struct.PyTreeNode):\n",
    "    a: int = 1\n",
    "    b: tuple[float] = (2.0, 3.0)\n",
    "    c: jax.Array = jax.numpy.array([4.0, 5.0, 6.0])\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return pytc.tree_repr(self)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return pytc.tree_str(self)\n",
    "\n",
    "    @property\n",
    "    def at(self):\n",
    "        return pytc.AtIndexer(self, where=())\n",
    "\n",
    "\n",
    "flax_tree = FlaxTree()\n",
    "\n",
    "print(f\"{flax_tree!r}\")\n",
    "print(f\"{flax_tree!s}\")\n",
    "print(pytc.tree_diagram(flax_tree))\n",
    "print(pytc.tree_summary(flax_tree))\n",
    "\n",
    "flax_tree.at[\"a\"].set(10)\n",
    "# FlaxTree(a=10, b=(2.0, 3.0), c=f32[3](μ=5.00, σ=0.82, ∈[4.00,6.00]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [8] `named_parameters()` like in `PyTreeClass`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NamedSequenceKey(idx=0, key='a'),) 1\n",
      "(NamedSequenceKey(idx=1, key='b'), SequenceKey(idx=0)) 2.0\n",
      "(NamedSequenceKey(idx=1, key='b'), SequenceKey(idx=1)) 3.0\n"
     ]
    }
   ],
   "source": [
    "import pytreeclass as pytc\n",
    "import jax\n",
    "\n",
    "\n",
    "class Tree(pytc.TreeClass):\n",
    "    a: int = 1\n",
    "    b: tuple[float, float] = (2.0, 3.0)\n",
    "\n",
    "\n",
    "tree = Tree()\n",
    "\n",
    "for path, leaf in jax.tree_util.tree_flatten_with_path(tree)[0]:\n",
    "    print(path, leaf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [9] Initializae parameters based on input\n",
    "In this example, a `Linear` layer with weight paraemter based on the shape of the input will be created.\n",
    "Since this requires parameter creation (i.e. `weight`) after instance initialization we will use `.at` to create a new instance with the added parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer before param is set:\tLazyLinear(out_features=1)\n",
      "Layer after param is set:\tLazyLinear(out_features=1, weight=[[1.]], bias=[0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytreeclass as pytc\n",
    "from typing import Any\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "\n",
    "\n",
    "class LazyLinear(pytc.TreeClass):\n",
    "    out_features: int\n",
    "\n",
    "    def param(self, name: str, value: Any):\n",
    "        # return the value if it exists, otherwise set it and return it\n",
    "        if name not in vars(self):\n",
    "            setattr(self, name, value)\n",
    "        return vars(self)[name]\n",
    "\n",
    "    def __call__(self, x: jax.Array, *, key: jr.KeyArray = jr.PRNGKey(0)):\n",
    "        weight = self.param(\"weight\", jnp.ones((x.shape[-1], self.out_features)))\n",
    "        bias = self.param(\"bias\", jnp.zeros((self.out_features,)))\n",
    "        return x @ weight + bias\n",
    "\n",
    "\n",
    "x = jnp.ones([10, 1])\n",
    "\n",
    "lazy_linear = LazyLinear(out_features=1)\n",
    "\n",
    "lazy_linear\n",
    "print(f\"Layer before param is set:\\t{lazy_linear}\")\n",
    "\n",
    "\n",
    "# first call will set the parameters\n",
    "_, linear = lazy_linear.at[\"__call__\"](x, key=jr.PRNGKey(0))\n",
    "\n",
    "print(f\"Layer after param is set:\\t{linear}\")\n",
    "# subsequent calls will use the same parameters and not set them again\n",
    "linear(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
