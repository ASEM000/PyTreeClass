{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🌲 Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛠️ Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip install pytreeclass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install development version**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip install git+https://github.com/ASEM000/PyTreeClass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📖 Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PyTreeClass` is a JAX-compatible `dataclass`-like decorator to create and operate on stateful JAX PyTrees.\n",
    "The package aims to achieve two goals:\n",
    "\n",
    "1) 🔒 To maintain safe and correct behaviour by using _immutable_ modules with _functional_ API.\n",
    "2) To achieve the **most intuitive** user experience in the `JAX` ecosystem by :\n",
    "   1) 🏗️ Defining layers similar to `PyTorch` or `TensorFlow` sublcassing style.\n",
    "   2) ☝️ Filtering\\Indexing layer values by using boolean masking similar to `jax.numpy.at[].{get,set,apply,...}`\n",
    "   3) 🎨 Visualize defined layers in plethora of ways for better debugging and sharing of information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⏩ Quick Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will demonstrate the basic features of `PyTreeClass` by constructing a simple `MLP` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.random as jr \n",
    "import jax.numpy as jnp \n",
    "import pytreeclass as pytc \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general any non `@treeclass` wrapper parameter should be defined as a dataclass field as follows:\n",
    "```python\n",
    "@pytc.treeclass\n",
    "class Linear :\n",
    "   weight : jnp.ndarray\n",
    "   bias   : jnp.ndarray\n",
    "\n",
    "   ...\n",
    "```\n",
    "To designate a node as non-trainable, you can use `pytreeclass.static_field(...)` in the field definition. This similar to assigning a field in dataclass using `dataclass.field(...)`\n",
    "\n",
    "Here, let's construct a `Linear` layer with `weight` and `bias` as trainable nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defininig Linear layer\n",
    "@pytc.treeclass\n",
    "class Linear :\n",
    "   weight : jnp.ndarray\n",
    "   bias   : jnp.ndarray\n",
    "\n",
    "   def __init__(self,key,in_dim,out_dim):\n",
    "       self.weight = jax.random.normal(key,shape=(in_dim, out_dim)) * jnp.sqrt(2/in_dim)\n",
    "       self.bias = jnp.ones((1,out_dim))\n",
    "\n",
    "   def __call__(self,x):\n",
    "       return x @ self.weight + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define a simple `MLP` class.\n",
    "Additionally, to demonstate how can we update internal state **_immutably_**,  we will define an additional state variable `num_calls` in the `MLP` class that gets incremented with each call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytc.treeclass\n",
    "class MLP:\n",
    "    layers: tuple[Linear] = ()\n",
    "    num_calls : float = 0.\n",
    "\n",
    "    def __init__(self,layers,*,key):\n",
    "        keys= jax.random.split(key,len(layers)-1)\n",
    "        for ki,in_dim,out_dim in zip(keys,layers[:-1],layers[1:]):\n",
    "            self.layers += (Linear(key=ki,in_dim=in_dim,out_dim=out_dim),)\n",
    "\n",
    "    def __call__(self,x):\n",
    "        self.num_calls+=1\n",
    "        *layers,last = self.layers\n",
    "        for layer in layers:\n",
    "            x = jax.nn.relu(layer(x))\n",
    "        return last(x)\n",
    "\n",
    "model = MLP([1,5,5,1],key=jr.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving forward, lets vizualize our model so far.\n",
    "For visualization `PyTreeClass` implements _pretty_ `.__repr__()`, `.__str__()`, `.tree_diagram()`, and `.summary()`\n",
    "\n",
    "- `.__repr__()` returns shorthand notation of created class.\n",
    "- `.__str__()`  returns full values of created class.\n",
    "- `.tree_diagram()` returns directory-tree-structure like.\n",
    "- `.summary()` returns parameter name, type, count, and size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model shorthand representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  layers=(\n",
       "    Linear(weight=f32[1,5],bias=f32[1,5]),\n",
       "    Linear(weight=f32[5,5],bias=f32[1,5]),\n",
       "    Linear(weight=f32[5,1],bias=f32[1,1])\n",
       "  ),\n",
       "  num_calls=0.0\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model full representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  layers=(\n",
      "    Linear(\n",
      "      weight=[[-1.6248673  -2.8383057   1.3969219   1.3169124  -0.40784812]],\n",
      "      bias=[[1. 1. 1. 1. 1.]]\n",
      "    ),\n",
      "    Linear(\n",
      "      weight=\n",
      "        [[ 0.0690082  -0.28695515  0.07628956 -0.0438102   0.00379491]\n",
      "         [ 1.50098    -0.11166672  1.1165049  -0.04066205  0.30811653]\n",
      "         [-0.7006985  -0.65002924 -0.35766158 -0.17880684 -0.6092746 ]\n",
      "         [-0.03396707  0.12827015 -0.10535626  0.50696546 -0.39020923]\n",
      "         [-0.1908553  -0.7502192  -1.964823   -0.02063693  0.33969834]],\n",
      "      bias=[[1. 1. 1. 1. 1.]]\n",
      "    ),\n",
      "    Linear(\n",
      "      weight=\n",
      "        [[ 0.98507565]\n",
      "         [ 0.99815285]\n",
      "         [-1.0687716 ]\n",
      "         [-0.19255024]\n",
      "         [-1.2108876 ]],\n",
      "      bias=[[1.]]\n",
      "    )\n",
      "  ),\n",
      "  num_calls=0.0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* directory-tree-structure like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\n",
      "    ├── layers=<class 'tuple'>\n",
      "    │   ├── layers_0=Linear\n",
      "    │   │   ├── weight=f32[1,5]\n",
      "    │   │   └── bias=f32[1,5]   \n",
      "    │   ├── layers_1=Linear\n",
      "    │   │   ├── weight=f32[5,5]\n",
      "    │   │   └── bias=f32[1,5]   \n",
      "    │   └── layers_2=Linear\n",
      "    │       ├── weight=f32[5,1]\n",
      "    │       └── bias=f32[1,1]   \n",
      "    └── num_calls=0.0   \n"
     ]
    }
   ],
   "source": [
    "print(model.tree_diagram())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────┬────────────┬───────┬───────┬───────────────┐\n",
      "│Name           │Type        │Param #│Size   │Config         │\n",
      "├───────────────┼────────────┼───────┼───────┼───────────────┤\n",
      "│layers/layers_0│tuple/Linear│10(0)  │40.00B │weight=f32[1,5]│\n",
      "│               │            │       │(0.00B)│bias=f32[1,5]  │\n",
      "├───────────────┼────────────┼───────┼───────┼───────────────┤\n",
      "│layers/layers_1│tuple/Linear│30(0)  │120.00B│weight=f32[5,5]│\n",
      "│               │            │       │(0.00B)│bias=f32[1,5]  │\n",
      "├───────────────┼────────────┼───────┼───────┼───────────────┤\n",
      "│layers/layers_2│tuple/Linear│6(0)   │24.00B │weight=f32[5,1]│\n",
      "│               │            │       │(0.00B)│bias=f32[1,1]  │\n",
      "├───────────────┼────────────┼───────┼───────┼───────────────┤\n",
      "│num_calls      │float       │1(0)   │24.00B │num_calls=0.0  │\n",
      "│               │            │       │(0.00B)│               │\n",
      "└───────────────┴────────────┴───────┴───────┴───────────────┘\n",
      "Total count :\t47(0)\n",
      "Dynamic count :\t47(0)\n",
      "Frozen count :\t0(0)\n",
      "--------------------------------------------------------------\n",
      "Total size :\t208.00B(0.00B)\n",
      "Dynamic size :\t208.00B(0.00B)\n",
      "Frozen size :\t0.00B(0.00B)\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return to training our model. First let's create some training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.linspace(0,1,100)[:,None]\n",
    "y = x**3 + jax.random.uniform(jax.random.PRNGKey(0),(100,1))*0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we differentiate the loss function `loss_func` with respect to model parameters by using `@jax.grad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.grad\n",
    "def loss_func(model,x,y):\n",
    "    return jnp.mean((model(x)-y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step is to define an update function to update the model parameters.\n",
    "\n",
    "Note: models wrapped with `@treeclass` support unary/binary operations, therefore we can update the model simply as the following:\n",
    "```python\n",
    "model - learning_rate * grad\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit \n",
    "def update(model,x,y):\n",
    "    jax.debug.print(\"{x}\",x=model.num_calls)\n",
    "    grad = loss_func(model,x,y)\n",
    "    # let increment the number of calls by 1\n",
    "    return model- 1e-3*grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets train for 20,000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImmutableInstanceError",
     "evalue": "Cannot set num_calls = Traced<ShapedArray(float32[], weak_type=True)>with<JVPTrace(level=2/1)> with\n  primal = Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n  tangent = Traced<ShapedArray(float32[], weak_type=True)>with<JaxprTrace(level=1/1)> with\n    pval = (ShapedArray(float32[], weak_type=True), None)\n    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x124e4ec30>, in_tracers=(Traced<ShapedArray(float32[], weak_type=True):JaxprTrace(level=1/1)>,), out_tracer_refs=[<weakref at 0x125fcf1a0; to 'JaxprTracer' at 0x1265ac6d0>], out_avals=[ShapedArray(float32[], weak_type=True)], primitive=xla_call, params={'device': None, 'backend': None, 'name': 'fn', 'donated_invars': (False,), 'inline': True, 'keep_unused': False, 'call_jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x126566730>, name_stack=NameStack(stack=(Transform(name='jvp'),)))). Use `.at['num_calls'].set(Traced<ShapedArray(float32[], weak_type=True)>with<JVPTrace(level=2/1)> with\n  primal = Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n  tangent = Traced<ShapedArray(float32[], weak_type=True)>with<JaxprTrace(level=1/1)> with\n    pval = (ShapedArray(float32[], weak_type=True), None)\n    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x124e4ec30>, in_tracers=(Traced<ShapedArray(float32[], weak_type=True):JaxprTrace(level=1/1)>,), out_tracer_refs=[<weakref at 0x125fcf1a0; to 'JaxprTracer' at 0x1265ac6d0>], out_avals=[ShapedArray(float32[], weak_type=True)], primitive=xla_call, params={'device': None, 'backend': None, 'name': 'fn', 'donated_invars': (False,), 'inline': True, 'keep_unused': False, 'call_jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x126566730>, name_stack=NameStack(stack=(Transform(name='jvp'),)))))` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImmutableInstanceError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m20_001\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model \u001b[39m=\u001b[39m update(model,x,y)\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "\u001b[1;32m/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb Cell 31\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(model, x, y)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m@jax\u001b[39m\u001b[39m.\u001b[39mjit \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate\u001b[39m(model,x,y):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     jax\u001b[39m.\u001b[39mdebug\u001b[39m.\u001b[39mprint(\u001b[39m\"\u001b[39m\u001b[39m{x}\u001b[39;00m\u001b[39m\"\u001b[39m,x\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mnum_calls)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     grad \u001b[39m=\u001b[39m loss_func(model,x,y)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# let increment the number of calls by 1\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m-\u001b[39m \u001b[39m1e-3\u001b[39m\u001b[39m*\u001b[39mgrad\n",
      "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "\u001b[1;32m/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb Cell 31\u001b[0m in \u001b[0;36mloss_func\u001b[0;34m(model, x, y)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m@jax\u001b[39m\u001b[39m.\u001b[39mgrad\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_func\u001b[39m(model,x,y):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39mmean((model(x)\u001b[39m-\u001b[39my)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[1;32m/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb Cell 31\u001b[0m in \u001b[0;36mMLP.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_calls\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb#X43sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m*\u001b[39mlayers,last \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/asem/pytreeclass/docs/notebooks/getting_started.ipynb#X43sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m layers:\n",
      "File \u001b[0;32m~/miniforge3/envs/dev-jax15/lib/python3.10/site-packages/pytreeclass/src/decorator.py:19\u001b[0m, in \u001b[0;36mtreeclass.<locals>.immutable_setattr.<locals>.wrapper\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, key, value):\n\u001b[1;32m     18\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__immutable_treeclass__:\n\u001b[0;32m---> 19\u001b[0m         \u001b[39mraise\u001b[39;00m ImmutableInstanceError(\n\u001b[1;32m     20\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot set \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m = \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m. Use `.at[\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m].set(\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m!r}\u001b[39;00m\u001b[39m)` instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m         )\n\u001b[1;32m     22\u001b[0m     \u001b[39m# execute original setattr\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     mutable_setattr(\u001b[39mself\u001b[39m, key, value)\n",
      "\u001b[0;31mImmutableInstanceError\u001b[0m: Cannot set num_calls = Traced<ShapedArray(float32[], weak_type=True)>with<JVPTrace(level=2/1)> with\n  primal = Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n  tangent = Traced<ShapedArray(float32[], weak_type=True)>with<JaxprTrace(level=1/1)> with\n    pval = (ShapedArray(float32[], weak_type=True), None)\n    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x124e4ec30>, in_tracers=(Traced<ShapedArray(float32[], weak_type=True):JaxprTrace(level=1/1)>,), out_tracer_refs=[<weakref at 0x125fcf1a0; to 'JaxprTracer' at 0x1265ac6d0>], out_avals=[ShapedArray(float32[], weak_type=True)], primitive=xla_call, params={'device': None, 'backend': None, 'name': 'fn', 'donated_invars': (False,), 'inline': True, 'keep_unused': False, 'call_jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x126566730>, name_stack=NameStack(stack=(Transform(name='jvp'),)))). Use `.at['num_calls'].set(Traced<ShapedArray(float32[], weak_type=True)>with<JVPTrace(level=2/1)> with\n  primal = Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n  tangent = Traced<ShapedArray(float32[], weak_type=True)>with<JaxprTrace(level=1/1)> with\n    pval = (ShapedArray(float32[], weak_type=True), None)\n    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x124e4ec30>, in_tracers=(Traced<ShapedArray(float32[], weak_type=True):JaxprTrace(level=1/1)>,), out_tracer_refs=[<weakref at 0x125fcf1a0; to 'JaxprTracer' at 0x1265ac6d0>], out_avals=[ShapedArray(float32[], weak_type=True)], primitive=xla_call, params={'device': None, 'backend': None, 'name': 'fn', 'donated_invars': (False,), 'inline': True, 'keep_unused': False, 'call_jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x126566730>, name_stack=NameStack(stack=(Transform(name='jvp'),)))))` instead."
     ]
    }
   ],
   "source": [
    "for _ in range(1,20_001):\n",
    "    model = update(model,x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💣💣💣💣\n",
    "\n",
    "The problem here is that model `__call__` modifies  `num_calls`  at each call, this means that the instance is not longer immutable. _This mutable behavior is not allowed in `pytreeclass`_. \n",
    "\n",
    "To solve this we can use `.at[...]` for functional updating the internal state as the following:\n",
    "```python\n",
    "...\n",
    "\n",
    "output_value, new_model = model.at[\"__call__\"]()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here the `num_calls` is updated after each model call, however to capture the updated `num_calls`  we need to return the updated instance `updated_model` along with the loss value for each loss_func call. \n",
    "\n",
    "Using `has_aux=True` in `jax.grad` we can output the updated_model along with the loss value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "\n",
    "@ft.partial(jax.value_and_grad, has_aux=True)\n",
    "def immutable_loss_func(model,x,y):\n",
    "    output,updated_model= model.at[\"__call__\"](x)\n",
    "    return jnp.mean((y-output)**2), updated_model\n",
    "\n",
    "@jax.jit\n",
    "def immutable_update(model,x,y):\n",
    "    (loss,updated_model),grads = immutable_loss_func(model,x,y)\n",
    "    return loss, updated_model-1e-3*grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,20_001):\n",
    "    loss,model = immutable_update(model,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000.0\n"
     ]
    }
   ],
   "source": [
    "print(model.num_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1417bd480>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output,model = model.at[\"__call__\"](x)\n",
    "\n",
    "plt.plot(x,y, '-',label=\"True\")\n",
    "plt.plot(x,output,'--', label=\"Prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have seen how to train an immutable model in a functional way. Immutable definition and functional API is useful in mitigating bugs or unintended behavior that arises from side effects ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('dev-jax15')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2499512ed2537f1f7868337b11978106d2ebb2fc6ab5814ee177db416ca4ea91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
