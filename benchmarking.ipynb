{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "\n",
    "import pytreeclass.src.tree_util as ptu\n",
    "import pytreeclass as pytc\n",
    "\n",
    "import treex as tx \n",
    "import treeo as to \n",
    "import equinox as eqx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Linear layer creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.67 ms ± 16.5 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "@pytc.treeclass\n",
    "class pytc_Linear :\n",
    "   weight : jnp.ndarray\n",
    "   bias   : jnp.ndarray\n",
    "\n",
    "   def __init__(self,key,in_dim,out_dim):\n",
    "       self.weight = jax.random.normal(key,shape=(in_dim, out_dim)) * jnp.sqrt(2/in_dim)\n",
    "       self.bias = jnp.ones((1,out_dim))\n",
    "\n",
    "   def __call__(self,x):\n",
    "       return x @ self.weight + self.bias\n",
    "\n",
    "@pytc.treeclass\n",
    "class pytc_MLP:\n",
    "\n",
    "    def __init__(self,key,in_dim,out_dim,hidden_dim):\n",
    "        keys= jax.random.split(key,3)\n",
    "        self.l1 = pytc_Linear(key=keys[0],in_dim=in_dim,out_dim=hidden_dim)\n",
    "        self.l2 = pytc_Linear(key=keys[1],in_dim=hidden_dim,out_dim=hidden_dim)\n",
    "        self.l3 = pytc_Linear(key=keys[2],in_dim=hidden_dim,out_dim=out_dim)\n",
    "\n",
    "    def __call__(self,x):\n",
    "        x = self.l1(x)\n",
    "        x = jax.nn.tanh(x)\n",
    "        x = self.l2(x)\n",
    "        x = jax.nn.tanh(x)\n",
    "        x = self.l3(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model = pytc_MLP(in_dim=1,out_dim=1,hidden_dim=10,key=jax.random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17 ms ± 58.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "class eqx_Linear(eqx.Module) :\n",
    "   weight : jnp.ndarray\n",
    "   bias   : jnp.ndarray\n",
    "\n",
    "   def __init__(self,key,in_dim,out_dim):\n",
    "       self.weight = jax.random.normal(key,shape=(in_dim, out_dim)) * jnp.sqrt(2/in_dim)\n",
    "       self.bias = jnp.ones((1,out_dim))\n",
    "\n",
    "   def __call__(self,x):\n",
    "       return x @ self.weight + self.bias\n",
    "\n",
    "class eqx_MLP(eqx.Module):\n",
    "    l1 : eqx_Linear\n",
    "    l2 : eqx_Linear\n",
    "    l3 : eqx_Linear\n",
    "\n",
    "    def __init__(self,key,in_dim,out_dim,hidden_dim):\n",
    "        keys= jax.random.split(key,3)\n",
    "        self.l1 = eqx_Linear(key=keys[0],in_dim=in_dim,out_dim=hidden_dim)\n",
    "        self.l2 = eqx_Linear(key=keys[1],in_dim=hidden_dim,out_dim=hidden_dim)\n",
    "        self.l3 = eqx_Linear(key=keys[2],in_dim=hidden_dim,out_dim=out_dim)\n",
    "\n",
    "    def __call__(self,x):\n",
    "        x = self.l1(x)\n",
    "        x = jax.nn.tanh(x)\n",
    "        x = self.l2(x)\n",
    "        x = jax.nn.tanh(x)\n",
    "        x = self.l3(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model = eqx_MLP(in_dim=1,out_dim=1,hidden_dim=10,key=jax.random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.78 ms ± 46.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "class tx_Linear(tx.Module) :\n",
    "   weight : jnp.ndarray = to.field(node=True)\n",
    "   bias   : jnp.ndarray = to.field(node=True)\n",
    "\n",
    "   def __init__(self,key,in_dim,out_dim):\n",
    "       self.weight = jax.random.normal(key,shape=(in_dim, out_dim)) * jnp.sqrt(2/in_dim)\n",
    "       self.bias = jnp.ones((1,out_dim))\n",
    "\n",
    "   def __call__(self,x):\n",
    "       return x @ self.weight + self.bias\n",
    "\n",
    "class tx_MLP(tx.Module):\n",
    "    l1 : tx_Linear = to.field(node=True)\n",
    "    l2 : tx_Linear = to.field(node=True)\n",
    "    l3 : tx_Linear = to.field(node=True)\n",
    "\n",
    "    def __init__(self,key,in_dim,out_dim,hidden_dim):\n",
    "        keys= jax.random.split(key,3)\n",
    "        self.l1 = tx_Linear(key=keys[0],in_dim=in_dim,out_dim=hidden_dim)\n",
    "        self.l2 = tx_Linear(key=keys[1],in_dim=hidden_dim,out_dim=hidden_dim)\n",
    "        self.l3 = tx_Linear(key=keys[2],in_dim=hidden_dim,out_dim=out_dim)\n",
    "\n",
    "    def __call__(self,x):\n",
    "        x = self.l1(x)\n",
    "        x = jax.nn.tanh(x)\n",
    "        x = self.l2(x)\n",
    "        x = jax.nn.tanh(x)\n",
    "        x = self.l3(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model = tx_MLP(in_dim=1,out_dim=1,hidden_dim=10,key=jax.random.PRNGKey(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark vanilla training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "881 ms ± 12.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "@pytc.treeclass\n",
    "class pytc_Linear :\n",
    "   weight : jnp.ndarray\n",
    "   bias   : jnp.ndarray\n",
    "\n",
    "   def __init__(self,key,in_dim,out_dim):\n",
    "       self.weight = jax.random.normal(key,shape=(in_dim, out_dim)) * jnp.sqrt(2/in_dim)\n",
    "       self.bias = jnp.ones((1,out_dim))\n",
    "\n",
    "   def __call__(self,x):\n",
    "       return x @ self.weight + self.bias\n",
    "\n",
    "@pytc.treeclass\n",
    "class pytc_MLP:\n",
    "\n",
    "    def __init__(self,key,in_dim,out_dim,hidden_dim):\n",
    "        keys= jax.random.split(key,3)\n",
    "        self.l1 = pytc_Linear(key=keys[0],in_dim=in_dim,out_dim=hidden_dim)\n",
    "        self.l2 = pytc_Linear(key=keys[1],in_dim=hidden_dim,out_dim=hidden_dim)\n",
    "        self.l3 = pytc_Linear(key=keys[2],in_dim=hidden_dim,out_dim=out_dim)\n",
    "\n",
    "    def __call__(self,x):\n",
    "        x = self.l1(x)\n",
    "        x = jax.nn.tanh(x)\n",
    "        x = self.l2(x)\n",
    "        x = jax.nn.tanh(x)\n",
    "        x = self.l3(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "pytc_model = pytc_MLP(in_dim=1,out_dim=1,hidden_dim=10,key=jax.random.PRNGKey(0))\n",
    "x = jnp.linspace(0,1,100)[:,None]\n",
    "y = x**3 + jax.random.uniform(jax.random.PRNGKey(0),(100,1))*0.01\n",
    "\n",
    "@jax.value_and_grad\n",
    "def loss_func(pytc_model, x, y):\n",
    "    return jnp.mean((pytc_model(x) - y)**2)\n",
    "\n",
    "@jax.jit\n",
    "def update(pytc_model, x, y, lr=1e-3):\n",
    "    value,grad = loss_func(pytc_model, x, y)\n",
    "    return value,jtu.tree_map(lambda x,y: x - lr * y, pytc_model, grad)\n",
    "\n",
    "for _ in range(1,20_001):\n",
    "    value,pytc_model = update(pytc_model, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857 ms ± 6.76 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "class tx_Linear(tx.Module) :\n",
    "   weight : jnp.ndarray = to.field(node=True)\n",
    "   bias   : jnp.ndarray = to.field(node=True)\n",
    "\n",
    "   def __init__(self,key,in_dim,out_dim):\n",
    "       self.weight = jax.random.normal(key,shape=(in_dim, out_dim)) * jnp.sqrt(2/in_dim)\n",
    "       self.bias = jnp.ones((1,out_dim))\n",
    "\n",
    "   def __call__(self,x):\n",
    "       return x @ self.weight + self.bias\n",
    "\n",
    "class tx_MLP(tx.Module):\n",
    "    l1 : tx_Linear = to.field(node=True)\n",
    "    l2 : tx_Linear = to.field(node=True)\n",
    "    l3 : tx_Linear = to.field(node=True)\n",
    "\n",
    "    def __init__(self,key,in_dim,out_dim,hidden_dim):\n",
    "        keys= jax.random.split(key,3)\n",
    "        self.l1 = tx_Linear(key=keys[0],in_dim=in_dim,out_dim=hidden_dim)\n",
    "        self.l2 = tx_Linear(key=keys[1],in_dim=hidden_dim,out_dim=hidden_dim)\n",
    "        self.l3 = tx_Linear(key=keys[2],in_dim=hidden_dim,out_dim=out_dim)\n",
    "\n",
    "    def __call__(self,x):\n",
    "        x = self.l1(x)\n",
    "        x = jax.nn.tanh(x)\n",
    "        x = self.l2(x)\n",
    "        x = jax.nn.tanh(x)\n",
    "        x = self.l3(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "tx_model = tx_MLP(in_dim=1,out_dim=1,hidden_dim=10,key=jax.random.PRNGKey(0))\n",
    "x = jnp.linspace(0,1,100)[:,None]\n",
    "y = x**3 + jax.random.uniform(jax.random.PRNGKey(0),(100,1))*0.01\n",
    "\n",
    "@jax.value_and_grad\n",
    "def loss_func(tx_model, x, y):\n",
    "    return jnp.mean((tx_model(x) - y)**2)\n",
    "\n",
    "@jax.jit\n",
    "def update(tx_model, x, y, lr=1e-3):\n",
    "    value,grad = loss_func(tx_model, x, y)\n",
    "    return value,jtu.tree_map(lambda x,y: x - lr * y, tx_model, grad)\n",
    "\n",
    "for _ in range(1,20_001):\n",
    "    value,tx_model = update(tx_model, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "873 ms ± 16.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "class eqx_Linear(eqx.Module) :\n",
    "   weight : jnp.ndarray\n",
    "   bias   : jnp.ndarray\n",
    "\n",
    "   def __init__(self,key,in_dim,out_dim):\n",
    "       self.weight = jax.random.normal(key,shape=(in_dim, out_dim)) * jnp.sqrt(2/in_dim)\n",
    "       self.bias = jnp.ones((1,out_dim))\n",
    "\n",
    "   def __call__(self,x):\n",
    "       return x @ self.weight + self.bias\n",
    "\n",
    "class eqx_MLP(eqx.Module):\n",
    "    l1 : eqx_Linear\n",
    "    l2 : eqx_Linear\n",
    "    l3 : eqx_Linear\n",
    "\n",
    "    def __init__(self,key,in_dim,out_dim,hidden_dim):\n",
    "        keys= jax.random.split(key,3)\n",
    "        self.l1 = eqx_Linear(key=keys[0],in_dim=in_dim,out_dim=hidden_dim)\n",
    "        self.l2 = eqx_Linear(key=keys[1],in_dim=hidden_dim,out_dim=hidden_dim)\n",
    "        self.l3 = eqx_Linear(key=keys[2],in_dim=hidden_dim,out_dim=out_dim)\n",
    "\n",
    "    def __call__(self,x):\n",
    "        x = self.l1(x)\n",
    "        x = jax.nn.tanh(x)\n",
    "        x = self.l2(x)\n",
    "        x = jax.nn.tanh(x)\n",
    "        x = self.l3(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "eqx_model = tx_MLP(in_dim=1,out_dim=1,hidden_dim=10,key=jax.random.PRNGKey(0))\n",
    "x = jnp.linspace(0,1,100)[:,None]\n",
    "y = x**3 + jax.random.uniform(jax.random.PRNGKey(0),(100,1))*0.01\n",
    "\n",
    "@jax.value_and_grad\n",
    "def loss_func(eqx_model, x, y):\n",
    "    return jnp.mean((eqx_model(x) - y)**2)\n",
    "\n",
    "@jax.jit\n",
    "def update(eqx_model, x, y, lr=1e-3):\n",
    "    value,grad = loss_func(eqx_model, x, y)\n",
    "    return value,jtu.tree_map(lambda x,y: x - lr * y, eqx_model, grad)\n",
    "\n",
    "for _ in range(1,20_001):\n",
    "    value,eqx_model = update(eqx_model, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.00066327, dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.00066327, dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('dev-jax15')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2499512ed2537f1f7868337b11978106d2ebb2fc6ab5814ee177db416ca4ea91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
